{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url=\"https://drive.google.com/drive/folders/1Kcnsas1hx3t361WxjiULyOdWg1DkoLE9?usp=drive_link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1Kcnsas1hx3t361WxjiULyOdWg1DkoLE9'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_url.split(\"/\")[-1].split(\"?\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MLOPS-E2E-Kidney_Classification\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MLOPS-E2E-Kidney_Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNN import components,config,constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNN.utils.common import read_yaml, create_directories, save_json\n",
    "from src.CNN.entity.config_entity import PrepareBaseModelConfig\n",
    "# from src.CNN.config.configuration import ConfigManager\n",
    "from src.CNN.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNN.entity.config_entity import TrainConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_roots])\n",
    "\n",
    "    def prepare_data_for_model(self)->TrainConfigs:\n",
    "        config=self.config.model_train\n",
    "        \n",
    "        return TrainConfigs(\n",
    "            config.model_file_path,\n",
    "            config.data_file_path,\n",
    "            config.train_history,\n",
    "            config.save_weights_path,\n",
    "            self.params.IMAGE_SIZE,\n",
    "            self.params.BATCH_SIZE,\n",
    "            self.params.EPOCHS,\n",
    "            self.params.CLASSES,\n",
    "            self.params.featurewise_center,\n",
    "            self.params.featurewise_std_normalization,\n",
    "            self.params.rotation_range,\n",
    "            self.params.width_shift_range,\n",
    "            self.params.height_shift_range,\n",
    "            self.params.horizontal_flip,\n",
    "            self.params.validation_split,\n",
    "            self.params.rescale,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from src.CNN import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "class_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, config: TrainConfigs):\n",
    "        self.config = config\n",
    "        self.data=[]\n",
    "        self.class_name=[]\n",
    "        \n",
    "    def train(self):\n",
    "        mlflow.keras.autolog()\n",
    "        with mlflow.start_run():\n",
    "            self.load_data(self,self.config.data_file_path)\n",
    "            train,valid=self.preprocess_data(self)\n",
    "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
    "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
    "            self.hist=model.fit(\n",
    "                train,\n",
    "                epochs=self.config.EPOCHS,\n",
    "                validation_data=(valid),\n",
    "            )\n",
    "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
    "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
    "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
    "            with open('./'+self.config.train_history, \"w\") as f:\n",
    "                json.dump(self.hist.history, f)\n",
    "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
    "            # mlflow.log_metrics(dict(self.hist.history))\n",
    "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
    "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
    "    @staticmethod\n",
    "    def preprocess_data(self,augmentation=True):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.data, self.class_name, test_size=0.2, random_state=42\n",
    "        )\n",
    "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
    "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
    "        # print(self.x_train[0].shape)\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=self.config.featurewise_center,\n",
    "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
    "            rotation_range=self.config.rotation_range,\n",
    "            width_shift_range=self.config.width_shift_range,\n",
    "            height_shift_range=self.config.height_shift_range,\n",
    "            horizontal_flip=self.config.horizontal_flip,\n",
    "            rescale=self.config.rescale,\n",
    "        )\n",
    "        validgen = ImageDataGenerator(\n",
    "            featurewise_center=self.config.featurewise_center,\n",
    "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
    "            rotation_range=self.config.rotation_range,\n",
    "            width_shift_range=self.config.width_shift_range,\n",
    "            height_shift_range=self.config.height_shift_range,\n",
    "            horizontal_flip=self.config.horizontal_flip,\n",
    "            rescale=self.config.rescale,\n",
    "        )\n",
    "        try:\n",
    "            datagen.fit(self.x_train)\n",
    "            validgen.fit(self.x_test)\n",
    "            # print(dir(train_gen.flow))\n",
    "            print(\"Data Augmentation Done\")\n",
    "            logger.info(\"Data Augmentation Done\")\n",
    "            self.x_train=np.array(self.x_train)\n",
    "            self.x_test=np.array(self.x_test)\n",
    "            self.y_train=np.array(self.y_train)\n",
    "            self.y_test=np.array(self.y_test)\n",
    "            train_data=datagen.flow(self.x_train,self.y_train)\n",
    "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
    "            return train_data,valid_data    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # logger.info(e)\n",
    "        # print(x_test_processed[0])\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_data(self,data):\n",
    "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
    "            for image in glob(folder+\"/*.jpg\"):\n",
    "                img = cv2.imread(image)\n",
    "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
    "                img = np.array(img)\n",
    "                self.data.append(img)\n",
    "                self.class_name.append(index)\n",
    "        print(\"Data Loaded\")\n",
    "        logger.info(\"Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 14:59:43,971 : INFO : common : Yaml File : config\\config.yaml Loaded Successfully : ]\n",
      "[2024-01-02 14:59:43,979 : INFO : common : Yaml File : params.yaml Loaded Successfully : ]\n",
      "[2024-01-02 14:59:43,982 : INFO : common : Created Directory : artifacts : ]\n",
      "Data Loaded\n",
      "[2024-01-02 14:59:53,441 : INFO : 1200640191 : Data Loaded : ]\n",
      "Data Augmentation Done\n",
      "[2024-01-02 14:59:59,457 : INFO : 1200640191 : Data Augmentation Done : ]\n",
      "[2024-01-02 15:00:01,985 : INFO : 1200640191 : Model is loaded from artifacts/prepare_base_model/base_model_update.h5 : ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/02 15:00:03 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.NumpyArrayIterator'>. Dataset logging skipped.\n",
      "2024/01/02 15:00:03 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.NumpyArrayIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 34s 1s/step - loss: 55.4224 - accuracy: 0.6148 - val_loss: 17.6651 - val_accuracy: 0.7876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/02 15:00:44 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2024/01/02 15:00:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 15:00:58,408 : WARNING : save : Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading. : ]\n",
      "[2024-01-02 15:01:02,128 : INFO : builder_impl : Assets written to: C:\\Users\\Shreyas\\AppData\\Local\\Temp\\tmpj6bcd5es\\model\\data\\model\\assets : ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/02 15:01:52 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 15:02:05,473 : WARNING : save : Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading. : ]\n",
      "[2024-01-02 15:02:09,078 : INFO : builder_impl : Assets written to: C:\\Users\\Shreyas\\AppData\\Local\\Temp\\tmp0ach15wa\\model\\data\\model\\assets : ]\n",
      "[2024-01-02 15:02:38,731 : INFO : 1200640191 : Saving history at artifacts/model_train/train_history.json : ]\n",
      "[2024-01-02 15:02:38,735 : INFO : 1200640191 : Model is saved at artifacts/prepare_base_model/base_model_update.h5 : ]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_config = ModelConfig()\n",
    "    train_config = model_config.prepare_data_for_model()\n",
    "    train_model = TrainModel(train_config)\n",
    "    # print(dict(train_model.config.__dict__))\n",
    "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
    "    mlflow.set_experiment(\"Default\")\n",
    "    train_model.train()\n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os,sys\n",
      "%pwd\n",
      "os.chdir(\"../\")\n",
      "from src.CNN import components,config,constants\n",
      "from src.CNN.utils.common import read_yaml, create_directories, save_json\n",
      "from src.CNN.entity.config_entity import PrepareBaseModelConfig\n",
      "# from src.CNN.config.configuration import ConfigManager\n",
      "from src.CNN.constants import *\n",
      "import numpy as np\n",
      "from src.CNN.entity.config_entity import TrainConfigs\n",
      "class ModelConfig:\n",
      "    def __init__(\n",
      "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
      "    ):\n",
      "        self.config = read_yaml(config_filepath)\n",
      "        self.params = read_yaml(params_filepath)\n",
      "\n",
      "        create_directories([self.config.artifacts_roots])\n",
      "\n",
      "    def prepare_data_for_model(self)->TrainConfigs:\n",
      "        config=self.config.model_train\n",
      "        \n",
      "        return TrainConfigs(\n",
      "            config.model_file_path,\n",
      "            config.data_file_path,\n",
      "            config.train_history,\n",
      "            config.save_weights_path,\n",
      "            self.params.IMAGE_SIZE,\n",
      "            self.params.BATCH_SIZE,\n",
      "            self.params.EPOCHS,\n",
      "            self.params.CLASSES,\n",
      "            self.params.featurewise_center,\n",
      "            self.params.featurewise_std_normalization,\n",
      "            self.params.rotation_range,\n",
      "            self.params.width_shift_range,\n",
      "            self.params.height_shift_range,\n",
      "            self.params.horizontal_flip,\n",
      "            self.params.validation_split,\n",
      "            self.params.rescale,\n",
      "        )\n",
      "from sklearn.model_selection import train_test_split\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
      "from src.CNN import logger\n",
      "from glob import glob\n",
      "import cv2\n",
      "import json\n",
      "from tensorflow.keras.models import load_model\n",
      "from keras.utils import to_categorical\n",
      "import mlflow\n",
      "data=[]\n",
      "class_name=[]\n",
      "class TrainModel:\n",
      "    def __init__(self, config: TrainConfigs):\n",
      "        mlflow.tensorflow.autolog()\n",
      "        self.config = config\n",
      "        self.data=[]\n",
      "        self.class_name=[]\n",
      "        \n",
      "    def train(self):\n",
      "        with mlflow.start_run():\n",
      "            self.load_data(self,self.config.data_file_path)\n",
      "            train,valid=self.preprocess_data(self)\n",
      "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
      "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
      "            history=model.fit(\n",
      "                train,\n",
      "                epochs=self.config.EPOCHS,\n",
      "                validation_data=(valid),\n",
      "            )\n",
      "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
      "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
      "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
      "            with open('./'+self.config.train_history, \"w\") as f:\n",
      "                json.dump(history.history, f)\n",
      "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
      "            mlflow.log_metrics(json.dumps(history.history))\n",
      "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "    @staticmethod\n",
      "    def preprocess_data(self,augmentation=True):\n",
      "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
      "            self.data, self.class_name, test_size=0.2, random_state=42\n",
      "        )\n",
      "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
      "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
      "        # print(self.x_train[0].shape)\n",
      "        datagen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        validgen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        try:\n",
      "            datagen.fit(self.x_train)\n",
      "            validgen.fit(self.x_test)\n",
      "            # print(dir(train_gen.flow))\n",
      "            print(\"Data Augmentation Done\")\n",
      "            logger.info(\"Data Augmentation Done\")\n",
      "            self.x_train=np.array(self.x_train)\n",
      "            self.x_test=np.array(self.x_test)\n",
      "            self.y_train=np.array(self.y_train)\n",
      "            self.y_test=np.array(self.y_test)\n",
      "            train_data=datagen.flow(self.x_train,self.y_train)\n",
      "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
      "            return train_data,valid_data    \n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "            # logger.info(e)\n",
      "        # print(x_test_processed[0])\n",
      "        \n",
      "    @staticmethod\n",
      "    def load_data(self,data):\n",
      "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
      "            for image in glob(folder+\"/*.jpg\"):\n",
      "                img = cv2.imread(image)\n",
      "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
      "                img = np.array(img)\n",
      "                self.data.append(img)\n",
      "                self.class_name.append(index)\n",
      "        print(\"Data Loaded\")\n",
      "        logger.info(\"Data Loaded\")\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "class TrainModel:\n",
      "    def __init__(self, config: TrainConfigs):\n",
      "        mlflow.tensorflow.autolog()\n",
      "        self.config = config\n",
      "        self.data=[]\n",
      "        self.class_name=[]\n",
      "        \n",
      "    def train(self):\n",
      "        with mlflow.start_run():\n",
      "            self.load_data(self,self.config.data_file_path)\n",
      "            train,valid=self.preprocess_data(self)\n",
      "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
      "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
      "            history=model.fit(\n",
      "                train,\n",
      "                epochs=self.config.EPOCHS,\n",
      "                validation_data=(valid),\n",
      "            )\n",
      "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
      "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
      "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
      "            with open('./'+self.config.train_history, \"w\") as f:\n",
      "                json.dump(history.history, f)\n",
      "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
      "            mlflow.log_metrics(json.dumps(history.history))\n",
      "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "    @staticmethod\n",
      "    def preprocess_data(self,augmentation=True):\n",
      "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
      "            self.data, self.class_name, test_size=0.2, random_state=42\n",
      "        )\n",
      "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
      "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
      "        # print(self.x_train[0].shape)\n",
      "        datagen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        validgen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        try:\n",
      "            datagen.fit(self.x_train)\n",
      "            validgen.fit(self.x_test)\n",
      "            # print(dir(train_gen.flow))\n",
      "            print(\"Data Augmentation Done\")\n",
      "            logger.info(\"Data Augmentation Done\")\n",
      "            self.x_train=np.array(self.x_train)\n",
      "            self.x_test=np.array(self.x_test)\n",
      "            self.y_train=np.array(self.y_train)\n",
      "            self.y_test=np.array(self.y_test)\n",
      "            train_data=datagen.flow(self.x_train,self.y_train)\n",
      "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
      "            return train_data,valid_data    \n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "            # logger.info(e)\n",
      "        # print(x_test_processed[0])\n",
      "        \n",
      "    @staticmethod\n",
      "    def load_data(self,data):\n",
      "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
      "            for image in glob(folder+\"/*.jpg\"):\n",
      "                img = cv2.imread(image)\n",
      "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
      "                img = np.array(img)\n",
      "                self.data.append(img)\n",
      "                self.class_name.append(index)\n",
      "        print(\"Data Loaded\")\n",
      "        logger.info(\"Data Loaded\")\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\"\n",
      "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"SHREYAS290601\"\n",
      "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"b06e74ec71a76270575d2e406cbc1d9f87f6a357\"\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "import mlflow\n",
      "import mlflow.keras\n",
      "class TrainModel:\n",
      "    def __init__(self, config: TrainConfigs):\n",
      "        mlflow.keras.autolog()\n",
      "        self.config = config\n",
      "        self.data=[]\n",
      "        self.class_name=[]\n",
      "        \n",
      "    def train(self):\n",
      "        with mlflow.start_run():\n",
      "            self.load_data(self,self.config.data_file_path)\n",
      "            train,valid=self.preprocess_data(self)\n",
      "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
      "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
      "            history=model.fit(\n",
      "                train,\n",
      "                epochs=self.config.EPOCHS,\n",
      "                validation_data=(valid),\n",
      "            )\n",
      "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
      "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
      "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
      "            with open('./'+self.config.train_history, \"w\") as f:\n",
      "                json.dump(history.history, f)\n",
      "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
      "            mlflow.log_metrics(json.dumps(history.history))\n",
      "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "    @staticmethod\n",
      "    def preprocess_data(self,augmentation=True):\n",
      "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
      "            self.data, self.class_name, test_size=0.2, random_state=42\n",
      "        )\n",
      "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
      "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
      "        # print(self.x_train[0].shape)\n",
      "        datagen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        validgen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        try:\n",
      "            datagen.fit(self.x_train)\n",
      "            validgen.fit(self.x_test)\n",
      "            # print(dir(train_gen.flow))\n",
      "            print(\"Data Augmentation Done\")\n",
      "            logger.info(\"Data Augmentation Done\")\n",
      "            self.x_train=np.array(self.x_train)\n",
      "            self.x_test=np.array(self.x_test)\n",
      "            self.y_train=np.array(self.y_train)\n",
      "            self.y_test=np.array(self.y_test)\n",
      "            train_data=datagen.flow(self.x_train,self.y_train)\n",
      "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
      "            return train_data,valid_data    \n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "            # logger.info(e)\n",
      "        # print(x_test_processed[0])\n",
      "        \n",
      "    @staticmethod\n",
      "    def load_data(self,data):\n",
      "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
      "            for image in glob(folder+\"/*.jpg\"):\n",
      "                img = cv2.imread(image)\n",
      "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
      "                img = np.array(img)\n",
      "                self.data.append(img)\n",
      "                self.class_name.append(index)\n",
      "        print(\"Data Loaded\")\n",
      "        logger.info(\"Data Loaded\")\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "history\n",
      "class TrainModel:\n",
      "    def __init__(self, config: TrainConfigs):\n",
      "        mlflow.keras.autolog()\n",
      "        self.config = config\n",
      "        self.data=[]\n",
      "        self.class_name=[]\n",
      "        \n",
      "    def train(self):\n",
      "        with mlflow.start_run():\n",
      "            self.load_data(self,self.config.data_file_path)\n",
      "            train,valid=self.preprocess_data(self)\n",
      "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
      "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
      "            hist=model.fit(\n",
      "                train,\n",
      "                epochs=self.config.EPOCHS,\n",
      "                validation_data=(valid),\n",
      "            )\n",
      "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
      "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
      "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
      "            with open('./'+self.config.train_history, \"w\") as f:\n",
      "                json.dump(hist.history, f)\n",
      "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
      "            mlflow.log_metrics(dict(history.history))\n",
      "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "    @staticmethod\n",
      "    def preprocess_data(self,augmentation=True):\n",
      "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
      "            self.data, self.class_name, test_size=0.2, random_state=42\n",
      "        )\n",
      "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
      "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
      "        # print(self.x_train[0].shape)\n",
      "        datagen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        validgen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        try:\n",
      "            datagen.fit(self.x_train)\n",
      "            validgen.fit(self.x_test)\n",
      "            # print(dir(train_gen.flow))\n",
      "            print(\"Data Augmentation Done\")\n",
      "            logger.info(\"Data Augmentation Done\")\n",
      "            self.x_train=np.array(self.x_train)\n",
      "            self.x_test=np.array(self.x_test)\n",
      "            self.y_train=np.array(self.y_train)\n",
      "            self.y_test=np.array(self.y_test)\n",
      "            train_data=datagen.flow(self.x_train,self.y_train)\n",
      "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
      "            return train_data,valid_data    \n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "            # logger.info(e)\n",
      "        # print(x_test_processed[0])\n",
      "        \n",
      "    @staticmethod\n",
      "    def load_data(self,data):\n",
      "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
      "            for image in glob(folder+\"/*.jpg\"):\n",
      "                img = cv2.imread(image)\n",
      "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
      "                img = np.array(img)\n",
      "                self.data.append(img)\n",
      "                self.class_name.append(index)\n",
      "        print(\"Data Loaded\")\n",
      "        logger.info(\"Data Loaded\")\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "class TrainModel:\n",
      "    def __init__(self, config: TrainConfigs):\n",
      "        mlflow.keras.autolog()\n",
      "        self.config = config\n",
      "        self.data=[]\n",
      "        self.class_name=[]\n",
      "        \n",
      "    def train(self):\n",
      "        with mlflow.start_run():\n",
      "            self.load_data(self,self.config.data_file_path)\n",
      "            train,valid=self.preprocess_data(self)\n",
      "            model=load_model('./artifacts/prepare_base_model/base_model_update.h5')\n",
      "            logger.info(\"Model is loaded from {}\".format(self.config.model_file_path))\n",
      "            hist=model.fit(\n",
      "                train,\n",
      "                epochs=self.config.EPOCHS,\n",
      "                validation_data=(valid),\n",
      "            )\n",
      "            # mlflow.log_params(params=dict(self.config.__dict__))\n",
      "            model.save('./'+self.config.save_weights_path+'/weights.h5')\n",
      "            mlflow.keras.log_model(model, \"MobileNetV2_Train\")\n",
      "            with open('./'+self.config.train_history, \"w\") as f:\n",
      "                json.dump(hist.history, f)\n",
      "                logger.info(\"Saving history at {}\".format(self.config.train_history))\n",
      "            mlflow.log_metrics(dict(hist.history))\n",
      "            logger.info(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "        # print(\"Model is saved at {}\".format(self.config.model_file_path))\n",
      "    @staticmethod\n",
      "    def preprocess_data(self,augmentation=True):\n",
      "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
      "            self.data, self.class_name, test_size=0.2, random_state=42\n",
      "        )\n",
      "        self.y_train = to_categorical(self.y_train, num_classes=self.config.CLASSES)\n",
      "        self.y_test = to_categorical(self.y_test, num_classes=self.config.CLASSES)\n",
      "        # print(self.x_train[0].shape)\n",
      "        datagen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        validgen = ImageDataGenerator(\n",
      "            featurewise_center=self.config.featurewise_center,\n",
      "            featurewise_std_normalization=self.config.featurewise_std_normalization,\n",
      "            rotation_range=self.config.rotation_range,\n",
      "            width_shift_range=self.config.width_shift_range,\n",
      "            height_shift_range=self.config.height_shift_range,\n",
      "            horizontal_flip=self.config.horizontal_flip,\n",
      "            rescale=self.config.rescale,\n",
      "        )\n",
      "        try:\n",
      "            datagen.fit(self.x_train)\n",
      "            validgen.fit(self.x_test)\n",
      "            # print(dir(train_gen.flow))\n",
      "            print(\"Data Augmentation Done\")\n",
      "            logger.info(\"Data Augmentation Done\")\n",
      "            self.x_train=np.array(self.x_train)\n",
      "            self.x_test=np.array(self.x_test)\n",
      "            self.y_train=np.array(self.y_train)\n",
      "            self.y_test=np.array(self.y_test)\n",
      "            train_data=datagen.flow(self.x_train,self.y_train)\n",
      "            valid_data=validgen.flow(self.x_test,self.y_test)\n",
      "            return train_data,valid_data    \n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "            # logger.info(e)\n",
      "        # print(x_test_processed[0])\n",
      "        \n",
      "    @staticmethod\n",
      "    def load_data(self,data):\n",
      "        for index,folder in enumerate(glob(\"./\"+self.config.data_file_path+\"/*\")):\n",
      "            for image in glob(folder+\"/*.jpg\"):\n",
      "                img = cv2.imread(image)\n",
      "                img = cv2.resize(img, tuple(self.config.IMAGE_SIZE[:-1]), interpolation=cv2.INTER_AREA)\n",
      "                img = np.array(img)\n",
      "                self.data.append(img)\n",
      "                self.class_name.append(index)\n",
      "        print(\"Data Loaded\")\n",
      "        logger.info(\"Data Loaded\")\n",
      "try:\n",
      "    model_config = ModelConfig()\n",
      "    train_config = model_config.prepare_data_for_model()\n",
      "    train_model = TrainModel(train_config)\n",
      "    # print(dict(train_model.config.__dict__))\n",
      "    mlflow.set_tracking_uri(uri=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\")\n",
      "    mlflow.set_experiment(\"Default\")\n",
      "    train_model.train()\n",
      "except Exception as e:\n",
      "    logger.exception(e)\n",
      "    raise e\n",
      "hist\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MLOPS-E2E-Kidney_Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/SHREYAS290601/E2E-MLFLOW-DVC-Kidney_classification.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"SHREYAS290601\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"b06e74ec71a76270575d2e406cbc1d9f87f6a357\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import mlflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('./artifacts/model_train/model_weights/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNN.entity.config_entity import *\n",
    "from src.CNN.utils.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalModelManager:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_roots])\n",
    "\n",
    "    def evaluate_model_config(self) -> EvalConfig:\n",
    "        config = self.config.model_eval\n",
    "        # print(config)\n",
    "        # create_directories([config.root_dir])\n",
    "\n",
    "        return EvalConfig(\n",
    "            path_to_model=config.model_weight_path,\n",
    "            training_data=config.data_file_path,\n",
    "            mlflow_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch=self.params.BATCH_SIZE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "from glob import glob\n",
    "import cv2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateModel:\n",
    "    def __init__(self, config:EvalConfig):\n",
    "        self.config=config\n",
    "        self.data=[]\n",
    "        self.class_name=[]\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.get_eval_data(self)\n",
    "        evaldata=self.create_eval_data(self)\n",
    "        self.model = load_model(\"./artifacts/model_train/model_weights/weights.h5\")\n",
    "        logger.info(f\"Model is loaded from {self.config.path_to_model}\")\n",
    "        self.score=self.model.evaluate(evaldata)\n",
    "        print(\"Loss: \",self.score[0])\n",
    "        print(\"Accuracy: \",self.score[1])\n",
    "        logger.info(f\"Loss: {self.score[0]}\")\n",
    "        logger.info(f\"Accuracy: {self.score[1]}\")\n",
    "        logger.info(f\"Accuracy is {self.score[1]*100}%\")\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"MobileNetV2\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_eval_data(self):\n",
    "        for index,folder in enumerate(glob(f\"./{self.config.training_data}/*\")):\n",
    "            for _,image in enumerate(glob(f\"{folder}/*.jpg\")):\n",
    "                if _<=20:\n",
    "                    img = cv2.imread(image)\n",
    "                    img = cv2.resize(img, tuple(self.config.params_image_size[:-1]), interpolation=cv2.INTER_AREA)\n",
    "                    img = np.array(img)\n",
    "                    self.data.append(img)\n",
    "                    self.class_name.append(index)\n",
    "        print(\"Data Loaded\")\n",
    "        logger.info(\"Data Loaded\")\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_eval_data(self):\n",
    "        evalgen=ImageDataGenerator(\n",
    "            featurewise_center=self.config.all_params.featurewise_center,\n",
    "            featurewise_std_normalization=self.config.all_params.featurewise_std_normalization,\n",
    "            rotation_range=self.config.all_params.rotation_range,\n",
    "            width_shift_range=self.config.all_params.width_shift_range,\n",
    "            height_shift_range=self.config.all_params.height_shift_range,\n",
    "            horizontal_flip=self.config.all_params.horizontal_flip,\n",
    "            rescale=self.config.all_params.rescale,\n",
    "            \n",
    "        )\n",
    "        evalgen.fit(self.data)\n",
    "        self.data=np.array(self.data)\n",
    "        self.class_name=np.array(to_categorical(self.class_name,num_classes=self.config.all_params.CLASSES))\n",
    "        return evalgen.flow(self.data,self.class_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-01 19:44:17,062 : INFO : common : Yaml File : config\\config.yaml Loaded Successfully : ]\n",
      "[2024-01-01 19:44:17,065 : INFO : common : Yaml File : params.yaml Loaded Successfully : ]\n",
      "[2024-01-01 19:44:17,066 : INFO : common : Created Directory : artifacts : ]\n",
      "Data Loaded\n",
      "[2024-01-01 19:44:17,742 : INFO : 1063786012 : Data Loaded : ]\n",
      "[2024-01-01 19:44:19,655 : INFO : 1063786012 : Model is loaded from artifacts/model_train/model_weights/weigths.h5 : ]\n",
      "3/3 [==============================] - 3s 700ms/step - loss: 1.6397 - accuracy: 0.9643\n",
      "Loss:  1.6396616697311401\n",
      "Accuracy:  0.9642857313156128\n",
      "[2024-01-01 19:44:23,523 : INFO : 1063786012 : Loss: 1.6396616697311401 : ]\n",
      "[2024-01-01 19:44:23,529 : INFO : 1063786012 : Accuracy: 0.9642857313156128 : ]\n",
      "[2024-01-01 19:44:23,536 : INFO : 1063786012 : Accuracy is 96.42857313156128% : ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/01 19:44:24 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-01 19:44:37,742 : WARNING : save : Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading. : ]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Shreyas\\AppData\\Local\\Temp\\tmpx7oce_iq\\model\\data\\model\\assets\n",
      "[2024-01-01 19:44:42,129 : INFO : builder_impl : Assets written to: C:\\Users\\Shreyas\\AppData\\Local\\Temp\\tmpx7oce_iq\\model\\data\\model\\assets : ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'MobileNetV2'.\n",
      "2024/01/01 19:45:50 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MobileNetV2, version 1\n",
      "Created version '1' of model 'MobileNetV2'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = EvalModelManager()\n",
    "    eval_config = config.evaluate_model_config()\n",
    "    evaluation = EvaluateModel(eval_config)\n",
    "    # print(eval_config)\n",
    "    evaluation.evaluate()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
